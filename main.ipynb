{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50326ee9",
   "metadata": {},
   "source": [
    "# BERT Narration Classification\n",
    "\n",
    "### Final Project - Vincent Gu\n",
    "### DATASCI 266 - Section 3 - Summer 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce33d8",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "As a model framework, BERT's pre-training on existing 'real' data such as Wikipedia provides an enormous repository\n",
    "of context and position based word embeddings suitable as a starting point for a myriad of language tasks. Tuning this \n",
    "pre-trained model can lead to increased task accuracy for specific tasks and datasets.\n",
    "\n",
    "However, how does BERT perform when presented with fictional text that differs substantially from the non-fiction\n",
    "(Wikipedia) data it was trained on? Furthermore, how well can BERT be fine-tuned with fictional text to increase \n",
    "performance at a classification text? Finally, how well can BERT pick up subtle variations in word meanings based on \n",
    "surrounding fictional context?\n",
    "\n",
    "To begin answering these questions, I leveraged the base BERT model with the science fiction novel 'Dark Age' by \n",
    "Pierce Brown. In the novel Brown crafts a dystopia in which mankind genetically engineered itsself into twelve distinct castes (colors in the book). Each color holds a certain function in society and inter-color marriage is forbidden and engineered to be biologically impossible. For example, Gold as the ruling class are engineered to be taller, stronger and smarter than Reds who toil as menial slave laborers.\n",
    "\n",
    "The novel contains narration from 5 different individuals of different colors and perspectives and the corresponding language task involves classifying an excerpt of the text based on which narrator the model believes the text came \n",
    "from. I then looked to improve model performance by fine-tuning. Finally, I analyzed various out-of-context words \n",
    "specific to the world Pierce Brown created to determine if the fine-tuned BERT could pick up nuanced word meanings,\n",
    "as represented in word embeddings, based on narrator.\n",
    "\n",
    "The five narrators (classification buckets) are:\n",
    "1. Darrow: A Red genetically 'carved' into a Gold warlord who led an uprising\n",
    "2. Virginia: The Gold Sovereign (ruler) of a more egalitarian/reformed society\n",
    "3. Ephraim: A Gray (foot soldier)\n",
    "4. Lyria: A Red disillusioned with Virginia's society\n",
    "5. Lysander: The last grandchild of the former Sovereign, a fascist slaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ff257",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Build and train a fine-tuned BERT model to classify excerpts from the novel based on its narrator\n",
    "- Determine if the model can pick up nuanced out-of-context word meanings based on the perspectives of each narrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc083091",
   "metadata": {},
   "source": [
    "## Project Directory\n",
    "\n",
    "* data (directory)\n",
    "  * dark-age-raw-text.txt\n",
    "* helpermodule (directory)\n",
    "  * data.py\n",
    "* models (directory - not in Github due to model size)\n",
    "* **main.ipynb**\n",
    "* BERT_base.py\n",
    "* train_BERT_base.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8f07e",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83da45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('helpermodule')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from helpermodule import data\n",
    "from data import get_chapter_data, get_excerpt_data, format_data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80cecd2",
   "metadata": {},
   "source": [
    "The custom helpermodule package processes the raw text into labeled data. We have 2,822 excerpts of 100 words. Here is an example of the label associated with a given excerpt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8e3e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Excerpts: 2822\n",
      "Darrow\n",
      "razor on the rooftops. Find it.” By the time the skinniest of them returns with my slingBlade in his trembling hands, another crowd has formed down the street. They’re trying to decide whether it’s worth rushing me. I take the blade from the boy. They see its shape. They run. I nod to the Red and, weighed down by forty kilos of dead armor, rush to ﬁnd my men. My miracle has turned into bedlam. Heliopolis is in chaos. Screams drift over the city. The streets are pitch dark. Gunshots crackle from conventional arms. Downed ships smolder and send black\n"
     ]
    }
   ],
   "source": [
    "excerpt_labels, excerpt_examples = get_excerpt_data(n_words=100)\n",
    "print(\"# Excerpts:\", len(excerpt_labels))\n",
    "print(excerpt_labels[2550])\n",
    "print(excerpt_examples[2550])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d8797",
   "metadata": {},
   "source": [
    "Here we generate train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec6e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n",
      "565\n",
      "2257\n",
      "565\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(excerpt_examples, excerpt_labels, test_size=.2, random_state=2457)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158288e1",
   "metadata": {},
   "source": [
    "# BERT Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b9bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from transformers import logging\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df066979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7a2e",
   "metadata": {},
   "source": [
    "## Training the Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d765c00e",
   "metadata": {},
   "source": [
    "To gauge various model training behaviors, the fine-tuned BERT model was trained using a number of batch sizes: **8, 18, 32, 64** and two excerpt sizes\" **100, 256**. In this setting, a single labeled observation (data point) would be comprised of either 100 or 256 words. Training details are saved as screenshots under the **training_screenshots** folder.\n",
    "\n",
    "As BERT's underlying transformer architecture requires significant computational resources, models were trained using GPU as opposed to CPU. Attempting to train on CPU look approximately two hours per epoch which was cut to between 5-15 minutes per epoch with GPU.\n",
    "\n",
    "Due to the size of these models, they were trained via commandline with the shell script **train_BERT.sh** which makes sucessive calls to **BERT_base.py**. These individual .py calls are parameterized with both the batch size and excerpt size. \n",
    "\n",
    "Overall, the models were able to learn a significant amount during training with final epoch validation accuracies around 80%. We see in initial epochs many models start off with about 20% validation accuracy - which indicates that at this point the model isn't performing any better at sorting into the five bins than it would if it was just randomly guessing. However, the substantial increases in validation accuracy over epochs demonstrates BERT's ability to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51aed4",
   "metadata": {},
   "source": [
    "*Best Performing Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ee4a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_bert = tf.keras.models.load_model('./models/bert_classification_model_16_256.h5', custom_objects={\"TFBertModel\": bert_model})\n",
    "x_train, x_test, y_train, y_test = format_data(n=100)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(excerpt_examples, excerpt_labels, test_size=.2, random_state=2457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32aa5f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 40s 2s/step - loss: 1.5981 - accuracy: 0.2885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.598059892654419, 0.28849557042121887]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert.evaluate([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask],\n",
    "                    y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67649260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 37s 2s/step\n"
     ]
    }
   ],
   "source": [
    "bert_cm = tf.math.confusion_matrix(\n",
    "    np.argmax(y_test, axis=1),\n",
    "    np.argmax(model_bert.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask]), axis=1),\n",
    ")\n",
    "sns.heatmap(bert_cm, annot=True, cbar=False, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de0be2",
   "metadata": {},
   "source": [
    "## Analysis of Out-of-Context Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f1c09ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f09c039efd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = bert_tokenizer(\"Gold\", return_tensors='tf')\n",
    "#print(bert_model(encoded_text))\n",
    "#print(model_bert(encoded_text))\n",
    "\n",
    "#Vector representation for \"Gold\"\n",
    "emb_1 = bert_model(encoded_text)[0][0, 1]\n",
    "model_bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
